{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import base64, os, requests, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganfd_df = pd.read_csv('../GANFD/image_lookup.csv')\n",
    "ganfd_dict = dict(zip(ganfd_df['full_ID'], ganfd_df['condition']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM = \"\"\"You are a helpful chat assistant. \n",
    "You are going to generate texts in response to images depicting fictional individuals.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PROMPT = \"Write a 50-word story about the individual inside the image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(image_dict, model, system_message, writing_prompt):\n",
    "\n",
    "    all_responses = []\n",
    "    image_list = []\n",
    "    condition_list = []\n",
    "\n",
    "    # Initialize API client\n",
    "    client = OpenAI()\n",
    "\n",
    "    for image_key, image_value in image_dict.items():\n",
    "        \n",
    "        image_path = '../GANFD/Images/' + image_key + '.jpg'\n",
    "        base64_image = encode_image(image_path)\n",
    "    \n",
    "        # Generate completions\n",
    "        completions = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": writing_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "                ]}\n",
    "            ],\n",
    "            max_tokens=150, \n",
    "            n = 50\n",
    "        )\n",
    "        \n",
    "        # Extract and collect responses\n",
    "        response_list = [choice.message.content for choice in completions.choices]\n",
    "        all_responses.extend(response_list)\n",
    "        image_list.extend([image_key for _ in range(len(response_list))])\n",
    "        condition_list.extend([image_value for _ in range(len(response_list))])\n",
    "\n",
    "    return image_list, condition_list, all_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text data\n",
    "image_column, condition_column, text_column = generate_text(ganfd_dict, \n",
    "                                                            MODEL_NAME, \n",
    "                                                            DEFAULT_SYSTEM, \n",
    "                                                            TEXT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame({\n",
    "    'image': image_column,\n",
    "    'condition': condition_column,  # Ensure the list matches the length of text_list\n",
    "    'text': text_column\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define non-compliance phrases\n",
    "non_compliance = [\n",
    "    \"Unable to identify\", \"Unable to view\", \"unable to provide\", \"cannot provide assumption\",\n",
    "    \"cannot provide information\", \"make assumptions about\", \"won't speculate or create stories\",\n",
    "    \"cannot see images\", \"cannot provide assistance\", \"can't provide assistance\", \"sorry\", \"Sorry\",\n",
    "    \"fictional\", \"image\", \"cannot assist\", \"can't assist\"\n",
    "]\n",
    "\n",
    "# Create regex pattern for non-compliance phrases\n",
    "regex_pattern = '|'.join([f'\\\\b{phrase}\\\\b' for phrase in non_compliance])\n",
    "\n",
    "# Filter the DataFrame\n",
    "non_compliance_count = response_df['text'].str.contains(regex_pattern, case=False, na=False).sum()\n",
    "data_filtered = response_df[~response_df['text'].str.contains(regex_pattern, case=False, na=False)]\n",
    "\n",
    "# Print the number of completions dropped\n",
    "print(f\"Number of completions dropped: {non_compliance_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered.to_csv(\"gpt4omini.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
